{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTwithPytorchAndColab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/AiScholarshipCodes/blob/master/MNISTwithPytorchAndColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nThnpeY2mAaL",
        "colab_type": "text"
      },
      "source": [
        "# Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEI9UlPMjAOJ",
        "colab_type": "code",
        "outputId": "02e89b25-5d28-41a4-f94d-9db20ee444d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install torch torchvision\n",
        "!pip3 install matplotlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2yB7nBAmH1Q",
        "colab_type": "text"
      },
      "source": [
        "#Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWm6gINXmNC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Wd8PGrmyfW",
        "colab_type": "code",
        "outputId": "b67dafda-d5bc-48c7-f09d-14e9de96b9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch version: 1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJcW_pzgzc0a",
        "colab_type": "text"
      },
      "source": [
        "# Select GPU mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRpsEh5uGRVQ",
        "colab_type": "code",
        "outputId": "057abf77-6466-4729-a492-61ca05810a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87yB5_QHzjp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIOKWpvAnA6p",
        "colab_type": "text"
      },
      "source": [
        "# Loading MNIST dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF7XzqPCnFsP",
        "colab_type": "code",
        "outputId": "94978941-1cbd-4135-acc8-e27ba7967587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "trainTransform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5, )),\n",
        "                              ])\n",
        "\n",
        "# Use the same transform for the validation data\n",
        "validTransform = trainTransform\n",
        "\n",
        "# Download and load the training data\n",
        "trainSet = MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=trainTransform)\n",
        "validSet = MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=validTransform)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 29110640.39it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 457870.39it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 145592.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7135076.58it/s]                            \n",
            "8192it [00:00, 174784.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne5bsDsDpF6Z",
        "colab_type": "code",
        "outputId": "a44040b2-a7a1-4542-a8dc-0ee2afc4bc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print (trainSet.train_data.shape)\n",
        "print (validSet.test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld10sIe7puim",
        "colab_type": "text"
      },
      "source": [
        "# Print training images and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4r6B_sDpsEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotImages (X, labels):\n",
        "  #Plot the first 5 images and their labels\n",
        "  for i, (img, y) in enumerate(zip(X, labels)):\n",
        "        plt.subplot(151 + i)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWwifIoprAwa",
        "colab_type": "code",
        "outputId": "e179324b-4b3e-4285-8094-dabe7de75b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "plotImages (trainSet.train_data[:5], trainSet.train_labels[:5].numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABbCAYAAABEQP/sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEmpJREFUeJzt3Xl0FFX2wPHvywJZWIMmgMNOQlhE\nVFBRAR0RdYYfygAi4DKMHgf4wSiKMnJ03PDnLoOI4gZBmVHHnRlHdFDkuCCKAjrIJpgIEiIBwp6Q\ndN7vj9vVSccACSRdr8n9nJOTpLqq+6bS/erWq/teGWstSiml/BfjdwBKKaWENshKKeUIbZCVUsoR\n2iArpZQjtEFWSilHaIOslFKO0AZZKaUc4WyDbIz5yBhTaIzZG/xa63dMfjPGpBhj3jTG7DPG5Bhj\nRvodkyuMMenB98s8v2PxmzFmvDFmmTGmyBiT5Xc8rjDGdDbGfGiM2WWM+d4YM9jvmCpytkEOGm+t\nbRD86uR3MA6YCRwE0oBRwFPGmK7+huSMmcCXfgfhiC3AVGC234G4whgTB7wN/AtIAa4H5hljMnwN\nrALXG2QVZIxJBoYAd1hr91prPwHmA1f5G5n/jDFXAAXAB37H4gJr7RvW2reA7X7H4pBMoCUwzVob\nsNZ+CHyKY58f1xvk+40x+caYT40x5/kdjM8ygBJr7bpyy1YCdTpDNsY0Au4BbvI7FhV1DNDN7yDK\nc7lBngy0B04CngH+aYzp4G9IvmoA7K6wbBfQ0IdYXHIv8Ly1drPfgSinrQV+Bm4xxsQbYwYA/YAk\nf8MK52yDbK1daq3dY60tstbORU4vfuN3XD7aCzSqsKwRsMeHWJxgjOkB9Aem+R2Lcpu1thi4DPgt\nsBW4GfgH4NSBPM7vAKrBIqcYddU6IM4Yk26tXR9cdgqwyseY/HYe0Bb40RgDchYRa4zpYq09zce4\nlIOstd8gWTEAxpjPgLn+RfRLTmbIxpgmxpiLjDEJxpg4Y8wooC+wwO/Y/GKt3Qe8AdxjjEk2xpwD\nXAq86G9kvnoG6AD0CH7NAt4BLvIzKL8FPzMJQCxygEoIVhnUacaY7sF9kWSMmQS0ALJ8DiuMkw0y\nEI+U7WwD8oEJwGUVLmjVReOARKQv7CVgrLW2zmbI1tr91tqt3hfSrVNord3md2w+ux04APwZuDL4\n8+2+RuSGq4Bc5PNzAXChtbbI35DCGZ2gXiml3OBqhqyUUnWONshKKeUIbZCVUsoR2iArpZQjtEFW\nSilHVKs2sZ6pbxNIrq1YnFDIPg7aoioPQKkL+wRgDzvzrbUnVmVd3SeVqwv7RT8/lavqe6VaDXIC\nyZxpLjj6qKLAUlu9CcPqwj4BWGhfy6nqurpPKlcX9ot+fipX1feKdlkopZQjtEFWSilHaIOslFKO\n0AZZKaUcoQ2yUko5os5PyRfNSn59OgC542TCqpW9ZWrXU5ZcA0DLmfUAiF30tQ/RKaWqSzNkpZRy\nhHMZsomTkGJPPKHSx9dOagtAIKkUgDYdfgYgaZzUom99TLLCr3u+EtomP7APgDNfvRmAjjd9XsNR\nR1Zpv1MBeHz2EwB0jJd9Vhp8fHnvOQCs7RkA4Ja2Z0U2wCiwb+iZADz40FOhZfdefjUAdtl/fYnJ\nDxse7g3A6pHyXoo3sQD0HXd9aJ3Et76IfGB1lGbISinliIhnyLGd0wGw9eMB2NKvCQAHzpIsNqWx\nfP/4lFcq2fqX3t0vN11+8ImLAVh68t8B+KH4QGidB/IuBKDlx9E9GX/xgJ4A3Pqk3LUpI17OBkqD\nufHG4mIAdpXWB+BU+UbRJb0ASFz0bei5SgsLaz/gQzhw6RnyvZlkYymzl0Q8hp97Si5yb/b/RPy1\nXbB14tkAfDT8IQCKbb3wFaL7oxK1NENWSilHRCRDDpxXdgPgx7JmAmXZ3dEqttI/+pcZvwcgbp8c\n0nu/Oh6Ahj+VhNatny/ZctKypcf0mpEW26gRAPv6ZgIwcZpk/+cn7g2uEX48zdopWc8HT0q/4Kd3\nPQ7Af56bBUCXeeND67afHPms1LOlr8Sd1KFAFsyO4IvHSFZuW8t74oLUNaGHPjBnRzAQf+1tJWdV\nKTHH9jmMBgcvkjPLnFHyN489bTEANzYNv0Xnyc9NACApV9qSgrOleqnN3+T9Wu+9ZbUeq2bISinl\nCG2QlVLKERHpsqi/dkvo568KWwGQEZ9XpW1vzpWSrY17pQwuq8NrAOwqldOKtMc/O+JzROv1ic0v\nnATAl71mVmn9e1K/BGBBAzn1Hp09AIC5bRcC0KjL9poO8ajcPfBVAB5cPSDirx3boQ0Aa/pJP0mP\nL64MPdbyy28r3eZ4sneYlPu9Pnh6cImUi84qkG6xhZfL6X1yzqrQNqVEp21jpOtuxq3y+elZX7o5\nY4J56DXZ/QE4tfGPAKy8bnrY9t56Z6eMACDlvVoOGM2QlVLKGRHJkEtyt4Z+nvHgMADuu1jK22K/\naQDAynEzwraZmt8dgO/7JwEQKMgFYGTvcQBk/0nWa8fKWoraP96Q6Jd6SLF+DOEXXkbnyITeyxZ2\nBuDba2W9RQcSAEhdJhesvt8pWU/8/y2S56nyfRxqV7wpOfJKtSTuuf1hvx/Y0MinSCKrcKCUGt55\nv5wZZMSHvxnmPitlo82/O/IZp6tMsFCgsP8pALx+28MAtIyT+s9rc6T8NeeRTgAkv7MCgEVJrQFY\n/GaGbJc+P+x5d69oBkBKrUVeRjNkpZRyRMQHhqTMkXKrE/8pR53A9h0AdO32BwBW9ZUj+Pxn+gGQ\nWhB+xDZLJCNu51/VVq059JBo6cUbtGYwALFD5eyiyW+ld7zLi1LOljFzEwAxm5YD0PRjed7i+6Tv\n7PXuZfVlfzhfTjEiOfFQ6bk9AOiT8EnEXrOitsnh/eitFgZ8iiSycq+UgUDnJ3oDgqT8z+tHbT49\nejNjT+546f/+YpLXFyyZ8bDvZfBPyRAZOJWUL+Wv3rWlLdfLGenS9PA+ZG/QWcen5XMVifM6zZCV\nUsoRvk0uFMgPz1SKd4f3k3Yd9R0A256SIzmlx28mY07vCkD+TdL36w2a+Urq0vlwbxcAtr8sFSrN\ndsrpQeN5MklS4+DzHOkInhZbP/Tz9hulLzV10TGFXi05AxPlNWOTIveiQXFtpZ9waEp4/2DiDztD\nPx+P77C4X0mlzqo+MuGUN6BqtSSL/PiY9JsmE12DpspbP0MqR9b+Tq5DeVUhnf8zBoDMSdnAL9sc\nz5ixb1e6fOp9Mo1t002ROx3XDFkppRzhzPSbnSfLMMbRJ0sFwZw2cjvxfsP+F4CGr0T3lJkVxSSV\nZYklD+0G4PPMNwD4oeQgADdNkelCm34sdZKpyTLVaE1kcme0kLuSZ9fAc1VVXMc9Yb8XrmkSsdfe\n9NdkAM6pL/nT87t/JQ8U7I5YDJEU21UqCXr+vfKpRIe/IdcQOrwenZ+rDY+WTSm79ndSZ7yrVPrH\nh60ZCUCnCdKmBPaEv+9ikuW9sH2oVHJd2kCqMWKQM7jMV6XN6ZgV+QtVmiErpZQjnMmQAwW7ANg+\nVmprf5wv/al/nvoCALddLhUGdrn0mLa6L3j0stE5Du9Av66hn9/LfDLssetumAhAw7cke/Gvard2\npS6r+TFgsSdI9U7eEOkbTbl8MwCLM54PriG12k/NvExiyIv+6oLK5AyS/fBas+XBJXItZuQGqTjI\neGADEH395rFpqQDMHVz2mfGqkLzMuN6FOcHl4WJ6yLWYbrNXAzA17fHgI3Jt5ZwVVwDQ6S553I99\noxmyUko5wpkM2VO6Uo5OV9x9CwB/u/MRAFacJZkywa6jrslSe5v+rIzgK9mYHbkga0D3e1eEfvbG\nzHsj8Gr6ljnebXmKy51MxBr/zywOpMjfnXyYdUr7SG22jZWRZZv6SzZzsKWUCcTUkzzm/T5yhd0b\ngLY1IOvdsVHOrHaUSr6UFCPrpy2VfkX/90LN2jFa5m94c8zDwSVyI4gxm6Suv/ga2S+BbT9GPLaa\nYBIkfm9eivIS/yTVSaaNVCOtHyPXCQb0l1r7ianPANA6TvqKvQw6EDzLNq/IfDmBgvW1EHnVaIas\nlFKOcC5D9ni39Rm/Vq54NnpA+gJfai9TLq26WkazZba6DoBOd8uxJbB+Y0TjrK6CqySDuT3tkdCy\n0uBcFV+9L31cranZfk2v9rS0XK/agtXyWulEbqReUWF8MA7JSOZMmQbA/PE9DrnN5GbPARATnJXs\ngJUKlC0B+Zue2HYeAP0X3ghAk+WyL1u8L7MJmhx532xbLVlRWqxk1vY4m9nNq6r4bOoTwSUJYY8v\n2dwWgFbZ0X0DV1soxflLi+JDy86sL//Ttxe+DIS/z8tbeEAy4PXBU0XvRg/LDsp7pskL/g//1QxZ\nKaUc4WyG7DGfSl/r/qFydbXXcLnNytLJMu58zfmSQY1qK3Pr7jo30hFWT4kkajQud+ucJYXSL9b+\nBZk3+lirKrwa5zWPdAsu+QqAURsvCa2TecMPQGSvJHe8Uq74d71f+v9b9frpiNss+lmqJba9K/2B\nzVZJNlRvwZfBNeT3DMJvr+P9XT9Nlrmhe9WX7OflvScdXfCOWzdF/ufe2VBFrR+Q79HeZx7Ik1r8\nO8deF1r2yCypuOge/EjN2y19yFMXDwIgI0vqk+PypJIr9SWZP+f8Vh8CcM0iea6K7yE/aIaslFKO\ncD5D9nhHxrTH5XvhrZJHJhk5LD7b9l8ADBwsfYlJb0bP2PztAZkT+lgrRbzMeO0DJwOw5lLpT3x3\nv9Rub5nZMbRuw53+jdBqd1v1++pacHRVAUl9t4X9fvuiIQBkULOVLH7xZgic2vOtSh+/8L9SW9tg\nWXT3HVdU/oajU9qdUek6Ff/Hey6V9d5pLXNXFFvJRxOz3bnRq2bISinlCOczZG8O3Q3D5Kpxtx7Z\nQFlm7JmxQzKFpLf97weqrkmfyl1UMoJ9vdXlZUk/B2eLW91TMuMLvh0OQPLFUnnSkOict6AmtXk7\n2ntRw92XJbW13eLD/65JuX0BaDxCZrOLthF5taEkUfLPilVH7bLk7MuFEbGaISullCOcy5BNT6kM\nWBccdfPsOXMB6JtwsNL1i6xcZf98RztZUJpbyxEeo+BIsphyx8Lp574EwEwyqvVUOfdITfPrVz8G\nlM2jfNoXMo9ry8HfHVOoyn2n1gvP+jxL5pwGQOrO43OujqPR8OXgGeKj/sZxOJohK6WUI3zPkOPa\ntQFgw+iWANw1XEbbDGmQf9jtpuTJ/bMWT5fJLZrO9X+UTZUEu/rKjybqlyh3MrgxS+7t1WGOPBa/\nVeZbyOt3IgApw2XU2YTWMlf0JUnS5zx/XxoAV38rdw4+4enDzQ5RN8UayT12ZsgIr+bv+hnNsdv0\nmpxJxpsVlT7e4iP5/GjfcZk9V3hzKB/dtZpI0AxZKaUcEfEM2bu32a7TWwAw/J4FAIxp8sZht7s5\nV45uS56UzDglS2oMm5ZGSWZ8GAlG/g2rL5wFwCd9pKJkfVFzAEY3zq50uxu29AFgwWdSiZJ+g1ZR\nHErABs9IojwF8Spq/tpjHlDWd+zdLaPXu1KHn5mj1w8q2tXe/X+++xEqpVQdoQ2yUko5ola7LOJa\nyCn3jtllF5nGtlsMwIiGeYfddvxPMkvQ10/J6fgJr8nQz5Q90d1FkfaRDP2e/MfeoWUPNg//m7wS\nv3MTssOWLy+S4+eIxdcDkDFaLk6k64CPKtvfa7/fIRyTwhQpbTw3YV9widx84L390hWYcb1MulTz\nN8eKfictlv99/Phf3rDBFZohK6WUI2o0Qz54kVxwOzhRpreb0vHfAAxI3HfIbTx5ARn223f+zQBk\n3r4GgJQCyR6PlyN+YJ3cXHL9sLahZV0myJSi310+o9JtMv89DoBOT8oRPmO5u2U7rvLK3lTd5U3l\nm7VbpvId0VCmf93fVQoM6m3a7E9g5ei7VCmlHFGjGXL2ZdK+rzv51UOuM7OgAwDTF8uE8iYgY4kz\np8qE6el5Mm3m8V7QXn6qzY4T5edBE3tVum4G0i/oYJeX84oWyqCaQI/j4xyr0YqtAEzY/GsAZrVa\n7Gc4UWna00MBGDFJbnLR4o7vAdhe0F1W+PwbX+ICzZCVUsoZNZohZ4yVwRoDx55+5HUrTB59vGfE\nyh/Np8nkOr+ZJpPttKfyocbRouSHHAA2B0cBD+TInzUV7qQX1wIw/LKBALzSUW5u0e8vIwBIGSk3\ndAgU7Ip4bJohK6WUI3yfXEgppSIpkC+TeR0c0gyAzo/+EYDV/Z8GYFDmtbKiD33JmiErpZQjNENW\nStVJXqacfo18H4RX5aRVFkopVecZa6te3WqM2Qbk1F44TmhjrT2xqivXkX0C1dgvuk8qV0f2i+6T\nylVpv1SrQVZKKVV7tMtCKaUcoQ2yUko5QhtkpZRyhDbISinlCG2QlVLKEdogK6WUI7RBVkopR2iD\nrJRSjtAGWSmlHPH/N1IAtLnim2UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43i2q93I0Go4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLoader = DataLoader(trainSet, batch_size=256, num_workers=0, shuffle=True)\n",
        "validLoader = DataLoader(validSet, batch_size=512, num_workers=0, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCJfz9u3Aqhh",
        "colab_type": "text"
      },
      "source": [
        "# Utilites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1n7Cp5DAu7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageBase(object):\n",
        "    \n",
        "    def __init__(self, value=0):\n",
        "        self.value = float(value) if value is not None else None\n",
        "       \n",
        "    def __str__(self):\n",
        "        return str(round(self.value, 4))\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.value\n",
        "    \n",
        "    def __format__(self, fmt):\n",
        "        return self.value.__format__(fmt)\n",
        "    \n",
        "    def __float__(self):\n",
        "        return self.value\n",
        "    \n",
        "\n",
        "class RunningAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    Keeps track of a cumulative moving average (CMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, value=0, count=0):\n",
        "        super(RunningAverage, self).__init__(value)\n",
        "        self.count = count\n",
        "        \n",
        "    def update(self, value):\n",
        "        self.value = (self.value * self.count + float(value))\n",
        "        self.count += 1\n",
        "        self.value /= self.count\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class MovingAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    An exponentially decaying moving average (EMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, alpha=0.99):\n",
        "        super(MovingAverage, self).__init__(None)\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def update(self, value):\n",
        "        if self.value is None:\n",
        "            self.value = float(value)\n",
        "        else:\n",
        "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
        "        return self.value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XZ1t6EW_6CB",
        "colab_type": "text"
      },
      "source": [
        "# Progress monitor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYVyTvXN__3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "class ProgressMonitor(object):\n",
        "    \"\"\"\n",
        "    Custom IPython progress bar for training\n",
        "    \"\"\"\n",
        "    \n",
        "    tmpl = \"\"\"\n",
        "        <p>Loss: {loss:0.4f}   {value} / {length}</p>\n",
        "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.display = display(self.html(0, 0), display_id=True)\n",
        "        \n",
        "    def html(self, count, loss):\n",
        "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
        "        \n",
        "    def update(self, count, loss):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeG-1hyUwla8",
        "colab_type": "text"
      },
      "source": [
        "#Lenet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38fG8t-bwqOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "     \n",
        "  def __init__(self):   \n",
        "        super(LeNet, self).__init__()\n",
        "        # Convolution (In LeNet, 32x32 images are given as input. Hence padding of 2 is done below)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Convolution\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Fully connected layer\n",
        "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
        "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
        "        \n",
        "  def forward(self, out):\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.conv1(out))  \n",
        "        # max-pooling with 2x2 grid\n",
        "        out = self.max_pool_1(out)\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.conv2(out))\n",
        "        # max-pooling with 2x2 grid\n",
        "        out = self.max_pool_2(out)\n",
        "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
        "        # read through https://stackoverflow.com/a/42482819/7551231\n",
        "        out = out.view(-1, 16*5*5)\n",
        "        # FC-1, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.fc1(out))\n",
        "        # FC-2, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.fc2(out))\n",
        "        # FC-3\n",
        "        out = self.fc3(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew2ijhjq0fgI",
        "colab_type": "text"
      },
      "source": [
        "# Instantiate the model and move it to CUDA device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U85NdUPX0nTi",
        "colab_type": "code",
        "outputId": "11623b1d-89f5-4078-cef4-e3b031b32943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "model = LeNet ()\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bEWM3YI02uB",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnEga2kQ0zJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmSPGf7h_mKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(optimizer, model, num_epochs=10, first_epoch=1):\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
        "        print('Epoch', epoch)\n",
        "\n",
        "        # train phase\n",
        "        model.train()\n",
        "\n",
        "        # create a progress bar\n",
        "        progress = ProgressMonitor(length=len(trainSet))\n",
        "\n",
        "        train_loss = MovingAverage()\n",
        "\n",
        "        for batch, targets in trainLoader:\n",
        "            # Move the training data to the GPU\n",
        "            batch = batch.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # clear previous gradient computation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward propagation\n",
        "            predictions = model(batch)\n",
        "\n",
        "            # calculate the loss\n",
        "            loss = criterion(predictions, targets)\n",
        "\n",
        "            # backpropagate to compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # update average loss\n",
        "            train_loss.update(loss)\n",
        "\n",
        "            # update progress bar\n",
        "            progress.update(batch.shape[0], train_loss)\n",
        "\n",
        "        print('Training loss:', train_loss)\n",
        "        train_losses.append(train_loss.value)\n",
        "\n",
        "\n",
        "        # validation phase\n",
        "        model.eval()\n",
        "\n",
        "        valid_loss = RunningAverage()\n",
        "\n",
        "        # keep track of predictions\n",
        "        y_pred = []\n",
        "\n",
        "        # We don't need gradients for validation, so wrap in \n",
        "        # no_grad to save memory\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for batch, targets in validLoader:\n",
        "\n",
        "                # Move the training batch to the GPU\n",
        "                batch = batch.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # forward propagation\n",
        "                predictions = model(batch)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss = criterion(predictions, targets)\n",
        "\n",
        "                # update running loss value\n",
        "                valid_loss.update(loss)\n",
        "\n",
        "                # save predictions\n",
        "                y_pred.extend(predictions.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "        print('Validation loss:', valid_loss)\n",
        "        valid_losses.append(valid_loss.value)\n",
        "\n",
        "        # Calculate validation accuracy\n",
        "        y_pred = torch.tensor(y_pred, dtype=torch.int64)\n",
        "        accuracy = torch.mean((y_pred == validSet.test_labels).float())\n",
        "        print('Validation accuracy: {:.4f}%'.format(float(accuracy) * 100))\n",
        "\n",
        "        # Save a checkpoint\n",
        "        #checkpoint_filename = 'checkpoints/mnist-{:03d}.pkl'.format(epoch)\n",
        "        #save_checkpoint(optimizer, model, epoch, checkpoint_filename)\n",
        "        if epoch == 10:\n",
        "          torch.save(model, 'mnistTrain.pth')\n",
        "    \n",
        "    return train_losses, valid_losses, y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVWh7x-FBEH4",
        "colab_type": "code",
        "outputId": "b2202f8b-2dcb-4f65-ccc1-12f4290f4793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1248
        }
      },
      "source": [
        "train_losses, valid_losses, y_pred = train(optimizer, model, num_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.3664   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.3664\n",
            "Validation loss: 0.0694\n",
            "Validation accuracy: 97.5900%\n",
            "Epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0659   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0659\n",
            "Validation loss: 0.0527\n",
            "Validation accuracy: 98.3400%\n",
            "Epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0434   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0434\n",
            "Validation loss: 0.0381\n",
            "Validation accuracy: 98.7400%\n",
            "Epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0349   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0349\n",
            "Validation loss: 0.0519\n",
            "Validation accuracy: 98.3600%\n",
            "Epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0328   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0328\n",
            "Validation loss: 0.0416\n",
            "Validation accuracy: 98.7000%\n",
            "Epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0255   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0255\n",
            "Validation loss: 0.0341\n",
            "Validation accuracy: 98.9100%\n",
            "Epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0224   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0224\n",
            "Validation loss: 0.0358\n",
            "Validation accuracy: 98.8800%\n",
            "Epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0196   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0196\n",
            "Validation loss: 0.0368\n",
            "Validation accuracy: 98.7700%\n",
            "Epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0173   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0173\n",
            "Validation loss: 0.0322\n",
            "Validation accuracy: 99.0800%\n",
            "Epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <p>Loss: 0.0158   60000 / 60000</p>\n",
              "        <progress value='60000' max='60000', style='width: 100%'>60000</progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.0158\n",
            "Validation loss: 0.0418\n",
            "Validation accuracy: 98.9100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LeNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWzywfPULHz8",
        "colab_type": "text"
      },
      "source": [
        "#Test on a random Image from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9JUs2suUfXV",
        "colab_type": "code",
        "outputId": "da84d9f0-1229-4415-e9b3-9cbeea728d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "device = 'cuda'\n",
        "model=torch.load('mnistTrain.pth')\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcImC_MSVR58",
        "colab_type": "code",
        "outputId": "8686257a-8aa8-4f00-cbd8-34b181811dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "loadedImg = validLoader.dataset.data[2512] # Change value in the box to test on different images\n",
        "plt.imshow(loadedImg)\n",
        "loadedImg = loadedImg.to(device)\n",
        "loadedImg = loadedImg[None, None]\n",
        "loadedImg = loadedImg.type('torch.cuda.FloatTensor') # instead of DoubleTensor\n",
        "\n",
        "out_predict = model(loadedImg)\n",
        "print (out_predict)\n",
        "pred = out_predict.max(1, keepdim=True)[1]\n",
        "print (pred)\n",
        "print ('\\n')\n",
        "print(\"\\t Predicted Label:\", pred.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ -635.4801,  -837.5001,    32.4767,   531.2853,  -714.0096,   145.5402,\n",
            "          -671.1224, -1334.0713,  1527.1113,   172.6783]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "tensor([[8]], device='cuda:0')\n",
            "\n",
            "\n",
            "\t Predicted Label: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIrwA0ERfiAowg8E9f8/Xn7e8xdqWgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}